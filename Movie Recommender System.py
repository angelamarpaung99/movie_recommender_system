# -*- coding: utf-8 -*-
"""TUBES_RECSYS.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1tLn_qOcZ8IE1r9cwJhUnMGhnk_YfNJzz
"""

from google.colab import drive
drive.mount('/content/gdrive')
import numpy as np
import pandas as pd
from sklearn.metrics import ndcg_score
from sklearn.model_selection import KFold
from itertools import chain
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import linear_kernel

drive = 'gdrive/My Drive/TUBES_RECSYS/'

"""## **Collaborative Filtering using Matrix Factorization**"""

# get ratings dataset
df_rating = pd.read_csv(drive + 'ratings.csv', sep=',')

# get movies dataset
df_movies = pd.read_csv(drive + 'movies.csv', sep=',')

# display first 5 rows of rating dataset
df_rating.head(5)

# display first 5 rows of movie dataset
df_movies.head(5)

dataset_rating = df_rating
dataset_movies = df_movies

# locate features and label for rating prediction
X = df_rating.iloc[:,[0,1]].values
y = df_rating.iloc[:,2].values

"""
Input:
    U     : a set of users
    D     : a set of items
    R     : a matrix of dimension |U| x |D| that contains all users ratings towards a movie
    P     : an initial matrix of association between users and features with dimension |U| x K
    Q     : an initial matrix of association between items and features with dimension |D| x K
    K     : the number of latent features
    steps : the maximum number of steps to perform the optimization
    alpha : the learning rate
    beta  : the regularization parameter
@OUTPUT:
    the final matrices P and Q
"""

def matrix_factorization(R, P, Q, K, steps=6, alpha=0.0002, beta=0.02):
    Q = Q.T # transpose matrix Q
    
    for step in range(steps):
      for i in range(len(R)):
          for j in range(len(R[i])):
              if R[i][j] > 0: # only minimise errors of the observed user-item pairs
                  eij = R[i][j] - np.dot(P[i,:],Q[:,j]) # count error between real rating and estimated rating
                  for k in range(K): 
                      P[i][k] = P[i][k] + alpha * (2 * eij * Q[k][j] - beta * P[i][k]) # set update rules for P
                      Q[k][j] = Q[k][j] + alpha * (2 * eij * P[i][k] - beta * Q[k][j]) # set update rules for Q
      eR = np.dot(P,Q)
      e = 0
      for i in range(len(R)):
          for j in range(len(R[i])):
              if R[i][j] > 0:
                  e = e + pow(R[i][j] - np.dot(P[i,:],Q[:,j]), 2) # check the overall error 
                  for k in range(K):
                      e = e + (beta/2) * ( pow(P[i][k],2) + pow(Q[k][j],2) ) # add beta to avoid overfitting
      if e < 0.001:
          break
    return P, Q.T

cv = KFold(n_splits=5, random_state=42, shuffle=True) # do cross-validation for 5 folds

df_user_items_pred = [] # initialize array that stores all dataframe of user and items prediction
score = [] # initialize NDCG score of test set

for train_index, test_index in cv.split(X):
    
    df_rating = dataset_rating
    
    X_train, X_test, y_train, y_test = X[train_index], X[test_index], y[train_index], y[test_index] # split into data train and data test
    real_val = y_test # save real rating of data test
    
    for i in range(len(test_index)):
        df_rating['rating'].iloc[test_index[i]] = 0 # mask data test result
    
    df_rating = df_rating.pivot(index='userId', columns='movieId', values='rating') # change dataframe to matrix of user and item (movie)
    df_rating = df_rating.fillna(0) # fill unrated movie's ratings with 0
    
    R = df_rating.to_numpy() 

    U = len(R) # intialize user latent features matrix
    D = len(R[0]) # initialize item latent features matrix
    K = 4 # set number of latent features

    P = np.random.rand(U,K) # initialize user latent features matrix with random values
    Q = np.random.rand(D,K) # initialize item latent features matrix with random values

    print("The Original Matrix")
    print(R)

    user_latent_features , item_latent_features  = matrix_factorization(R, P, Q, K)

    user_items_matrix = np.dot(user_latent_features, item_latent_features.T)
    print("\nThe Approximation matrix by MF")
    print(user_items_matrix)
    
    df_user_items =  pd.DataFrame(user_items_matrix, columns = df_rating.columns, index = df_rating.index) # set user items matrix as dataframe
    df_user_items_pred.append(df_user_items)
    
    predicted = [] # initialize empty list for predicted data test
    for i in range(len(X_test)):
        predicted.append(df_user_items.loc[X_test[i][0]][X_test[i][1]]) # get rating prediction of data test
    
    predicted = np.asarray([predicted]) 
    real_val = np.asarray([real_val])
    score.append(ndcg_score(real_val,predicted))  # evaluate NDCG score of data test prediction

# print NDCG score for 5 fold validation and its average
print("NDCG score : ", score)
print("NDCG average score : ", np.mean(score))

# get user items dataframe of best data prediction
df_user_items = df_user_items_pred[score.index(max(score))]
df_user_items

# Get top-20 recommendations for all user
def recommendation(df_user_items, dataset_rating, dataset_movies):
    n_recommendations = 20 # set number of recommendations
    n_users = dataset_rating.userId.unique().shape[0] # get all unique users id count

    for i in range(1,n_users+1):
      user_rating_pred = df_user_items.loc[i].sort_values(ascending=False) # get user rating prediction
      user_rated = (dataset_rating[dataset_rating['userId'] == i].merge(dataset_movies, how = 'left', on='movieId').
                      sort_values(['rating'], ascending=False)) # get user rated movie information

      recommendations = (dataset_movies[~dataset_movies['movieId'].isin(user_rated['movieId'])].
            merge(pd.DataFrame(user_rating_pred).reset_index(), how = 'left',
                  on = 'movieId').
            rename(columns = {i: 'Predictions'}).
            sort_values('Predictions', ascending = False).
                          iloc[:n_recommendations, :-1]
                        ) # get 20-top rated movie recommendation for user that hasn't being watched by user

      print("User id = ", i)
      print("Recommended movies: ")
      for j in range(recommendations.shape[0]):
        print(j+1,".", recommendations['title'].values[j])
      print("\n")

recommendation(df_user_items, dataset_rating, dataset_movies)

"""# **Content Based Filtering (clustering over Movie genre)**"""

# get movie dataset
df_movies = dataset_movies
df_movies

# display all unique genres in movie dataset
movie_genres = df_movies['genres'].str.split("|").to_list()
flatten_list = list(chain.from_iterable(movie_genres)) 
set(flatten_list)

# delete movie data where genre is not listed
df_movies = df_movies[df_movies['genres'] != "(no genres listed)"]
df_movies

# function to count cosine similarity of a specific column towards movie_id

def count_cosine_similarity(column, movies_id):
  # weight keyword tf-idf of column in dataset movies
  tf = TfidfVectorizer(analyzer='word', ngram_range=(1, 1), min_df=0, token_pattern=r"(?u)\w[\w-]*\w")
  tfidf_matrix = tf.fit_transform(column)

  # calculate cosine similarities to find the column values similarity
  cosine_similarities = linear_kernel(tfidf_matrix, tfidf_matrix)

  # get dataframe of movie id to column cosine similarities
  recommender_df = pd.DataFrame(cosine_similarities, columns=column, index=movies_id)

  # delete duplicate column (duplicated genres) in dataframe
  recommender_df = recommender_df.loc[:,~recommender_df.columns.duplicated()]
  return recommender_df

recommender_df = count_cosine_similarity(df_movies.genres, df_movies.movieId)
recommender_df

# get one-hot-encoded table of movie genres
df_movie_genre = pd.get_dummies(df_movies['genres'])

# get total of users id in dataframe
n_users = len(df_user_items.index)

# get user-genre similarities dataframe
df_user_genre = pd.DataFrame(columns = recommender_df.columns)
for i in range(1,n_users+1):
    df_user_genre.loc[i] = df_movie_genre.mul(df_user_items.loc[i], axis=0).mean() # multiply one-hot-encoded movie column with user-items dataframe from recommender 1
df_user_genre

# initialize user-movie similarity dataframe
df_user_movie_sim_1 = pd.DataFrame(columns = df_user_items.columns)

# get user-movie similarity 
for i in range(1,n_users+1):
  df_user_movie_sim_1.loc[i] = recommender_df.mul(df_user_genre.loc[i]).sum(axis=1)
df_user_movie_sim_1

# get user recommendation 
recommendation(df_user_movie_sim_1, dataset_rating, dataset_movies)

"""# **Content-Based Filtering (Clustering over tags)**"""

# get ratings dataset
df_tags = pd.read_csv(drive+'tags.csv', sep=',')
df_tags.head(10)

# lowercase folding tag column values
df_tags['tag'] = df_tags['tag'].str.lower()

# get unique values of tag column
x = df_tags['tag'].str.split("|").to_list()
flatten_list = list(chain.from_iterable(x)) 
set(flatten_list)

# sort tag values by movie id
df_tags = df_tags.sort_values(by=['movieId'])
df_tags

# get movie dataset
df_movies = dataset_movies

# add tag column in movie dataset and set it with empty values
df_movies["tag"] = np.nan
df_movies

# set value of tag in movie dataset
for index,row in df_tags.iterrows():
  idx = df_movies.index[df_movies["movieId"] == row[1]].tolist()[0]
  if pd.isnull(df_movies["tag"].iloc[idx]):
    df_movies["tag"].iloc[idx] = row[2]
  else:
    if row[2] not in df_movies["tag"].iloc[idx]:
      df_movies["tag"].iloc[idx] += "|"+row[2]

# delete movie rows where tag column value is empty
df_movies = df_movies[~df_movies["tag"].isnull()].iloc[:,[0,1,3]]
df_movies

# get dataframe of cosine similarity
recommender_df = count_cosine_similarity(df_movies.tag, df_movies.movieId)
recommender_df

# get total users from user_movie_matrix from recommender 2
n_users = len(df_user_movie_sim_1.index)

# get one-hot-encoded movie tag
df_movie_tag = pd.get_dummies(df_movies['tag'])

# get user similarity values to all tag
df_user_tag = pd.DataFrame(columns = recommender_df.columns)
for i in range(1,n_users+1):
    df_user_tag.loc[i] = df_movie_tag.mul(df_user_movie_sim_1.loc[i], axis=0).mean() # multiply one-hot-encoded movie tag with user_movie_matrix from recommender 2
df_user_tag

# initialize new user-movie similarity dataframe
df_user_movie_sim_2 = pd.DataFrame(columns = df_user_items.columns)

# map user-movie similarity to dataframe
for i in range(1,n_users+1):
  df_user_movie_sim_2.loc[i] = recommender_df.mul(df_user_tag.loc[i]).sum(axis=1)

df_user_movie_sim_2

# convert all nan values with 0
df_user_movie_sim_2 = df_user_movie_sim_2.fillna(0)
df_user_movie_sim_2

# get top-20 recommended movies for every user
recommendation(df_user_movie_sim_2, dataset_rating, dataset_movies)

